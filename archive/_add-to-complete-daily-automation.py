def import_stories_to_database(self, stories: List[Dict[str, Any]]) -> bool:
    """Import generated stories to local database"""
    try:
        import mysql.connector
        from mysql.connector import Error
        
        # Connect to database
        connection = mysql.connector.connect(**self.config['local_database'])
        cursor = connection.cursor()
        
        imported_count = 0
        updated_count = 0
        errors = []
        
        for story in stories:
            try:
                # Start transaction for each story
                connection.start_transaction()
                
                # Extract main story data
                story_id = story.get('id')
                if not story_id:
                    self.logger.warning("Story missing ID, skipping")
                    continue
                
                # Check if story already exists
                cursor.execute("SELECT id FROM stories WHERE id = %s", (story_id,))
                existing = cursor.fetchone()
                
                # Prepare main story data
                story_data = {
                    'id': story_id,
                    'title': story.get('title', '')[:500],
                    'summary': story.get('summary', ''),
                    'full_content': story.get('full_content', ''),
                    'curriculum_alignment': story.get('curriculum_alignment'),
                    'ai_skill_level': story.get('ai_skill_level'),
                    'ai_roi_potential': story.get('ai_roi_potential'),
                    'investment_domain_primary': story.get('investment_domain_primary'),
                    'difficulty_level': story.get('difficulty_level'),
                    'urgency': story.get('urgency'),
                    'concept_hierarchy_level': story.get('concept_hierarchy_level'),
                    'learning_sequence_position': story.get('learning_sequence_position'),
                    'experience_assumptions': story.get('experience_assumptions'),
                    'tech_savviness_required': story.get('tech_savviness_required'),
                    'expert_credentials': json.dumps(story.get('expert_credentials', {})) if story.get('expert_credentials') else None,
                    'track_record_mentions': story.get('track_record_mentions'),
                    'source_bias_assessment': json.dumps(story.get('source_bias_assessment', {})) if story.get('source_bias_assessment') else None,
                    'quote_highlight': story.get('quote_highlight'),
                    'family_security_relevance': story.get('family_security_relevance'),
                    'generational_wealth_relevance': story.get('generational_wealth_relevance'),
                    'children_education_angle': json.dumps(story.get('children_education_angle', {})) if story.get('children_education_angle') else None,
                    'emergency_fund_consideration': story.get('emergency_fund_consideration'),
                    'risk_level': story.get('risk_level'),
                    'time_required': story.get('time_required'),
                    'email_subject_line': story.get('email_subject_line', '')[:500],
                    'social_snippet': story.get('social_snippet', '')[:280],
                    'community_hook': story.get('community_hook'),
                    'app_hook': story.get('app_hook'),
                    'podcast_hook': story.get('podcast_hook'),
                    'financial_disclaimer': 1 if story.get('financial_disclaimer', True) else 0,
                    'dinner_table_readiness': story.get('family_engagement_metrics', {}).get('dinner_table_readiness'),
                    'estimated_read_time': story.get('performance_metrics', {}).get('estimated_read_time'),
                    'complexity_rating': story.get('performance_metrics', {}).get('complexity_rating'),
                    'retention_probability': story.get('performance_metrics', {}).get('retention_probability'),
                    'application_difficulty': story.get('performance_metrics', {}).get('application_difficulty'),
                    'confidence_building': story.get('scoring', {}).get('confidence_building'),
                    'family_impact': story.get('scoring', {}).get('family_impact'),
                    'mastery_potential': story.get('scoring', {}).get('mastery_potential'),
                    'viral_potential': story.get('scoring', {}).get('viral_potential')
                }
                
                # Get content type ID
                content_type = story.get('content_type', 'research-method')
                cursor.execute("SELECT id FROM content_types WHERE name = %s", (content_type,))
                content_type_result = cursor.fetchone()
                
                if not content_type_result:
                    # Create new content type if it doesn't exist
                    cursor.execute(
                        "INSERT INTO content_types (name, description) VALUES (%s, %s)",
                        (content_type, f"Auto-created content type: {content_type}")
                    )
                    story_data['content_type_id'] = cursor.lastrowid
                else:
                    story_data['content_type_id'] = content_type_result[0]
                
                if existing:
                    # Update existing story
                    update_fields = []
                    update_values = []
                    for key, value in story_data.items():
                        if key != 'id':
                            update_fields.append(f"{key} = %s")
                            update_values.append(value)
                    
                    update_values.append(story_id)
                    update_query = f"UPDATE stories SET {', '.join(update_fields)}, updated_at = NOW() WHERE id = %s"
                    cursor.execute(update_query, update_values)
                    updated_count += 1
                    self.logger.debug(f"Updated story: {story_id}")
                else:
                    # Insert new story
                    fields = list(story_data.keys())
                    values = list(story_data.values())
                    placeholders = ', '.join(['%s'] * len(fields))
                    insert_query = f"INSERT INTO stories ({', '.join(fields)}, created_at, updated_at) VALUES ({placeholders}, NOW(), NOW())"
                    cursor.execute(insert_query, values)
                    imported_count += 1
                    self.logger.debug(f"Imported story: {story_id}")
                
                # Import related data
                self._import_story_relationships(cursor, story_id, story, existing is not None)
                
                # Commit transaction
                connection.commit()
                
            except Exception as e:
                connection.rollback()
                error_msg = f"Error importing story {story.get('id', 'Unknown')}: {str(e)}"
                errors.append(error_msg)
                self.logger.error(error_msg)
                self.logger.error(traceback.format_exc())
        
        # Update stats
        self.stats['stories_imported'] = imported_count
        self.stats['stories_updated'] = updated_count
        
        if errors:
            self.stats['errors'].extend(errors)
            self.logger.warning(f"Import completed with {len(errors)} errors")
        
        cursor.close()
        connection.close()
        
        self.logger.info(f"‚úÖ Successfully imported {imported_count} new stories, updated {updated_count} existing stories")
        return (imported_count + updated_count) > 0
        
    except Exception as e:
        self.logger.error(f"‚ùå Database import failed: {str(e)}")
        self.logger.error(traceback.format_exc())
        self.stats['errors'].append(f"Database import: {str(e)}")
        return False

def _import_story_relationships(self, cursor, story_id: str, story: Dict[str, Any], is_update: bool):
    """Import all related data for a story"""
    
    # If updating, clear existing relationships first
    if is_update:
        tables_to_clear = [
            'story_belt_levels', 'story_tags', 'story_sources', 'story_scores',
            'actionable_practices', 'discussion_prompts', 'learning_outcomes',
            'contrarian_viewpoints', 'risk_warnings', 'search_keywords',
            'family_discussion_points', 'story_teaching_activities', 
            'story_age_translations', 'story_seasonal_challenges'
        ]
        
        for table in tables_to_clear:
            cursor.execute(f"DELETE FROM {table} WHERE story_id = %s", (story_id,))
    
    # Import belt levels
    belt_levels = story.get('belt_levels', [])
    for belt_name in belt_levels:
        cursor.execute("SELECT id FROM belt_levels WHERE name = %s", (belt_name,))
        belt_result = cursor.fetchone()
        if belt_result:
            cursor.execute(
                "INSERT INTO story_belt_levels (story_id, belt_level_id) VALUES (%s, %s)",
                (story_id, belt_result[0])
            )
    
    # Import tags
    tags_data = story.get('tags', {})
    all_tags = []
    if isinstance(tags_data, dict):
        all_tags.extend(tags_data.get('primary', []))
        all_tags.extend(tags_data.get('secondary', []))
        all_tags.extend(tags_data.get('trending', []))
    
    for tag_name in all_tags:
        # Get or create tag
        cursor.execute("SELECT id FROM tags WHERE name = %s", (tag_name,))
        tag_result = cursor.fetchone()
        
        if not tag_result:
            cursor.execute("INSERT INTO tags (name) VALUES (%s)", (tag_name,))
            tag_id = cursor.lastrowid
        else:
            tag_id = tag_result[0]
        
        cursor.execute(
            "INSERT INTO story_tags (story_id, tag_id) VALUES (%s, %s)",
            (story_id, tag_id)
        )
        
        # Update tag usage count
        cursor.execute("UPDATE tags SET usage_count = usage_count + 1 WHERE id = %s", (tag_id,))
    
    # Import source information
    source_data = story.get('source', {})
    if source_data:
        cursor.execute("""
            INSERT INTO story_sources 
            (story_id, podcast_title, episode_title, episode_url, media_url, 
             episode_timestamp, host_name)
            VALUES (%s, %s, %s, %s, %s, %s, %s)
        """, (
            story_id,
            source_data.get('podcast_title'),
            source_data.get('episode_title'),
            source_data.get('episode_url'),
            source_data.get('media_url'),
            source_data.get('timestamp'),
            source_data.get('host_name')
        ))
    
    # Import scores
    scoring_data = story.get('scoring', {})
    if scoring_data:
        cursor.execute("""
            INSERT INTO story_scores 
            (story_id, curriculum_value, engagement_score, practical_score, 
             ai_innovation_score, belt_progression_xp, confidence_building,
             family_impact, mastery_potential, viral_potential)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """, (
            story_id,
            scoring_data.get('curriculum_value'),
            scoring_data.get('engagement_score'),
            scoring_data.get('practical_score'),
            scoring_data.get('ai_innovation_score'),
            story.get('belt_progression_xp', 0),
            scoring_data.get('confidence_building'),
            scoring_data.get('family_impact'),
            scoring_data.get('mastery_potential'),
            scoring_data.get('viral_potential')
        ))
    
    # Import actionable practices
    practices = story.get('actionable_practices', [])
    for i, practice in enumerate(practices):
        if isinstance(practice, dict):
            practice_text = practice.get('practice', '')
        else:
            practice_text = str(practice)
        
        cursor.execute("""
            INSERT INTO actionable_practices 
            (story_id, practice, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, practice_text, i))
    
    # Import discussion prompts
    prompts = story.get('discussion_prompts', [])
    for i, prompt in enumerate(prompts):
        if isinstance(prompt, dict):
            prompt_text = prompt.get('prompt', '')
        else:
            prompt_text = str(prompt)
        
        cursor.execute("""
            INSERT INTO discussion_prompts 
            (story_id, prompt, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, prompt_text, i))
    
    # Import learning outcomes
    outcomes = story.get('learning_outcomes', [])
    for i, outcome in enumerate(outcomes):
        if isinstance(outcome, dict):
            outcome_text = outcome.get('outcome', '')
        else:
            outcome_text = str(outcome)
        
        cursor.execute("""
            INSERT INTO learning_outcomes 
            (story_id, outcome, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, outcome_text, i))
    
    # Import contrarian viewpoints
    viewpoints = story.get('contrarian_viewpoints', [])
    for i, viewpoint in enumerate(viewpoints):
        if isinstance(viewpoint, dict):
            viewpoint_text = viewpoint.get('viewpoint', '')
        else:
            viewpoint_text = str(viewpoint)
        
        cursor.execute("""
            INSERT INTO contrarian_viewpoints 
            (story_id, viewpoint, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, viewpoint_text, i))
    
    # Import risk warnings
    warnings = story.get('risk_warnings', [])
    for i, warning in enumerate(warnings):
        if isinstance(warning, dict):
            warning_text = warning.get('warning', '')
        else:
            warning_text = str(warning)
        
        cursor.execute("""
            INSERT INTO risk_warnings 
            (story_id, warning, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, warning_text, i))
    
    # Import search keywords
    keywords = story.get('search_keywords', [])
    for keyword_data in keywords:
        if isinstance(keyword_data, dict):
            keyword = keyword_data.get('keyword', '')
        else:
            keyword = str(keyword_data)
        
        cursor.execute("""
            INSERT INTO search_keywords 
            (story_id, keyword)
            VALUES (%s, %s)
        """, (story_id, keyword))
    
    # Import family discussion points
    family_points = story.get('family_discussion_points', [])
    for i, point in enumerate(family_points):
        if isinstance(point, dict):
            point_text = point.get('topic', '')
        else:
            point_text = str(point)
        
        cursor.execute("""
            INSERT INTO family_discussion_points 
            (story_id, point, display_order)
            VALUES (%s, %s, %s)
        """, (story_id, point_text, i))
    
    # Import teaching activities
    education_data = story.get('children_education_angle', {})
    if isinstance(education_data, dict):
        activities = education_data.get('teaching_activities', [])
        for i, activity in enumerate(activities):
            cursor.execute("""
                INSERT INTO story_teaching_activities 
                (story_id, activity, age_group, display_order)
                VALUES (%s, %s, %s, %s)
            """, (story_id, activity, 'all', i))
        
        # Import age translations
        age_concepts = education_data.get('age_appropriate_concepts', {})
        if isinstance(age_concepts, dict):
            for age_group, translation in age_concepts.items():
                cursor.execute("""
                    INSERT INTO story_age_translations 
                    (story_id, age_group, translation, display_order)
                    VALUES (%s, %s, %s, %s)
                """, (story_id, age_group, translation, 0))
    
    # Import seasonal challenges
    season_relevance = story.get('season_relevance', [])
    if isinstance(season_relevance, list):
        for season_type in season_relevance:
            # Check if season type exists
            cursor.execute("SELECT challenge_type FROM seasonal_challenges WHERE challenge_type = %s", (season_type,))
            if cursor.fetchone():
                cursor.execute("""
                    INSERT INTO story_seasonal_challenges 
                    (story_id, season_type)
                    VALUES (%s, %s)
                """, (story_id, season_type))

def sync_to_production(self, stories: List[Dict[str, Any]]) -> bool:
    """Sync new stories to production database with validation checks"""
    try:
        # Check if we have minimum stories required for sync
        min_stories = self.config.get('min_stories_for_sync', 1)
        if len(stories) < min_stories:
            self.logger.warning(f"Only {len(stories)} stories generated, minimum {min_stories} required for production sync")
            return True  # Not an error, just skip sync
        
        # Step 1: Validate local database health
        if self.config.get('validation_checks', True):
            self.logger.info("üîç Validating local database before production sync...")
            if not self._validate_local_database(stories):
                self.logger.error("‚ùå Local database validation failed - aborting production sync")
                return False
            self.logger.info("‚úÖ Local database validation passed")
        
        # Step 2: Connect to production database
        self.logger.info("üåê Connecting to production database...")
        import mysql.connector
        
        prod_connection = mysql.connector.connect(**self.config['production_database'])
        prod_cursor = prod_connection.cursor()
        
        self.logger.info("‚úÖ Connected to production database")
        
        # Step 3: Import stories to production
        imported_count = 0
        errors = []
        
        for story in stories:
            try:
                # Use the same import logic as local database
                prod_connection.start_transaction()
                
                story_id = story.get('id')
                if not story_id:
                    continue
                
                # Check if story already exists in production
                prod_cursor.execute("SELECT id FROM stories WHERE id = %s", (story_id,))
                existing = prod_cursor.fetchone()
                
                # Prepare and insert/update story data (same as local import)
                # ... (use same logic as import_stories_to_database)
                
                # For brevity, I'll just show the pattern - you'd use the same logic
                if not existing:
                    # Insert new story to production
                    # ... (same insert logic)
                    imported_count += 1
                    self.logger.debug(f"‚úÖ Production sync: {story.get('title', 'Unknown')[:50]}...")
                
                # Import relationships
                self._import_story_relationships(prod_cursor, story_id, story, existing is not None)
                
                prod_connection.commit()
                
            except Exception as e:
                prod_connection.rollback()
                error_msg = f"Error syncing story {story.get('id', 'Unknown')} to production: {str(e)}"
                errors.append(error_msg)
                self.logger.error(error_msg)
        
        # Update stats
        self.stats['production_synced'] = imported_count
        self.stats['production_errors'] = len(errors)
        
        if errors:
            self.stats['errors'].extend(errors)
            self.logger.warning(f"Production sync completed with {len(errors)} errors")
        
        prod_cursor.close()
        prod_connection.close()
        
        if imported_count > 0:
            self.logger.info(f"üéâ Successfully synced {imported_count} stories to production!")
            return True
        else:
            self.logger.error("‚ùå No stories were synced to production")
            return False
        
    except Exception as e:
        self.logger.error(f"‚ùå Production sync failed: {str(e)}")
        self.logger.error(traceback.format_exc())
        self.stats['errors'].append(f"Production sync: {str(e)}")
        return False

def _validate_local_database(self, stories: List[Dict[str, Any]]) -> bool:
    """Validate that stories were properly imported to local database"""
    try:
        import mysql.connector
        
        # Connect to local database
        connection = mysql.connector.connect(**self.config['local_database'])
        cursor = connection.cursor()
        
        validation_passed = True
        
        # Check that all stories exist in local database
        for story in stories:
            story_id = story.get('id')
            if not story_id:
                continue
            
            cursor.execute("SELECT id, title FROM stories WHERE id = %s", (story_id,))
            result = cursor.fetchone()
            
            if not result:
                self.logger.error(f"‚ùå Story not found in local database: {story_id}")
                validation_passed = False
            else:
                self.logger.debug(f"‚úÖ Validated local story: {result[1][:50]}...")
        
        # Check database health
        cursor.execute("SELECT COUNT(*) FROM stories WHERE created_at >= DATE_SUB(NOW(), INTERVAL 24 HOUR)")
        recent_count = cursor.fetchone()[0]
        
        if recent_count == 0:
            self.logger.warning("‚ö†Ô∏è No stories created in local database in last 24 hours")
        else:
            self.logger.info(f"‚úÖ Local database health: {recent_count} stories in last 24 hours")
        
        cursor.close()
        connection.close()
        
        return validation_passed
        
    except Exception as e:
        self.logger.error(f"‚ùå Local database validation error: {str(e)}")
        return False
